--- 
layout: post
title: (Estimation) Notes on Kalman Filter
description: 
date: 2020-06-23
categories: [Engineering]
tag: [Engineering, Filter, Kalman Filter, Linear Filter,
Prediction, Correction, Bayesian]
use_math: true
comments: true
---
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#org58d0eaa">1. Introduction</a></li>
<li><a href="#org2de8678">2. Bayesian Rule</a></li>
<li><a href="#org6c01022">3. Joint Distribution</a></li>
<li><a href="#orga5fbff1">4. Conditional Distribution</a></li>
<li><a href="#org466bcf8">5. Recursive Bayes Filter</a></li>
<li><a href="#org9cb8881">6. Kalman Filter</a>
<ul>
<li><a href="#org3d1efce">6.1. Prediction step</a></li>
<li><a href="#org6c30b8e">6.2. Correction Step</a></li>
<li><a href="#orgd138f50">6.3. Pseudo code</a></li>
</ul>
</li>
<li><a href="#org5f534f4">7. Extended Kalman Filter</a>
<ul>
<li><a href="#org4452ac6">7.1. Pseudo code</a></li>
</ul>
</li>
<li><a href="#org5706b9e">8. References</a></li>
</ul>
</div>
</div>


<div id="outline-container-org58d0eaa" class="outline-2">
<h2 id="org58d0eaa"><span class="section-number-2">1</span> Introduction</h2>
<div class="outline-text-2" id="text-1">
<p>
칼만 필터(kalman filter)는 노이즈가 존재하는 데이터에서 상태변수를 추정하는 대표적인 상태 추정 알고리즘이다. 실제 세상에서 획득하는 데이터에는 항상 노이즈가 존재하므로 공학 분야에서 칼만 필터는 매우 널리 사용된다.
</p>

<p>
칼만 필터를 이해하기에 앞서 <b>Bayesian Rule, Joint Distribution, Conditional Distribution, Recursive Bayes Filter와 같은 선행 지식들을 먼저 설명한 후 칼만 필터에 대해 설명한다.</b>
</p>
</div>
</div>

<div id="outline-container-org2de8678" class="outline-2">
<h2 id="org2de8678"><span class="section-number-2">2</span> Bayesian Rule</h2>
<div class="outline-text-2" id="text-2">
<p>
Bayesian Rule은 다음과 같이 조건부확률 간 관계를 의미한다.
</p>

\begin{equation}
  \begin{aligned}
    P(B|A) = \frac{P(B\cap A)}{P(A)} = \frac{P(A|B)P(B)}{P(A)}
  \end{aligned}
\end{equation}
<p>
이 때 $P(B|A)$를 Posterior라고 하고 $P(A|B)$를 Likelihood, $P(B)$를 Prior라고 한다. 예를 들어, 로봇의 위치를 $\mathbf{x}$, 로봇의 센서를 통해 관측한 값을 $\mathbf{z}$이라고 했을 때 주어진 관측 데이터를 바탕으로 현재 로봇이 $\mathbf{x}$에 위치할 확률 $p(\mathbf{x}|\mathbf{z})$는
</p>

\begin{equation}
  \begin{aligned}
    p(\mathbf{x}|\mathbf{z}) = \frac{p(\mathbf{z}|\mathbf{x})p(\mathbf{x})}{p(\mathbf{z})} = \eta \cdot p(\mathbf{z}|\mathbf{x})p(\mathbf{x})
  \end{aligned}
\end{equation}
<p>
과 같다. $p(\mathbf{z}|\mathbf{x})$는 $\mathbf{x}$위치에서 해당 관측값이 나올 확률을 의미하며 마지막으로 $p(\mathbf{x})$는 로봇이 $\mathbf{x}$위치에 존재할 확률을 의미한다. $1/p(\mathbf{z})$는 $&eta;$로 치환하여 주로 표기하며 $p(\mathbf{z}|\mathbf{x})p(\mathbf{x})$확률분포의 넓이가 1이 되도록 정규화해주는 Normalization Factor라고 한다.
</p>
</div>
</div>

<div id="outline-container-org6c01022" class="outline-2">
<h2 id="org6c01022"><span class="section-number-2">3</span> Joint Distribution</h2>
<div class="outline-text-2" id="text-3">
<p>
두 개의 확률변수 $a,b$가 있을 때 다변수 확률분포$p(a, b) &sim; \mathcal{N}(\mathbf{\boldsymbol{\mu}}, \boldsymbol{\Sigma})$는 다음과 같이 나타낼 수 있다.
</p>

\begin{equation}
  \begin{aligned}
    p(a, b) = \frac{1}{\sqrt{(2\pi)^{n}|\boldsymbol{\Sigma}|}}\exp{-\frac{1}{2}\bigg(\begin{bmatrix} a - \mathbb{E}(a) \\ b - \mathbb{E}(b) \end{bmatrix}\bigg)^{T}\boldsymbol{\Sigma}^{-1}\bigg(\begin{bmatrix} a - \mathbb{E}(a) \\ b - \mathbb{E}(b) \end{bmatrix}\bigg)}
  \end{aligned}
\end{equation}
<p>
이 때 평균은 $\mathbf{\boldsymbol{\mu}} = \begin{bmatrix}\mathbb{E}(a) \\ \mathbb{E}(b) \end{bmatrix}$이고 분산은 $\boldsymbol{\Sigma}= \begin{bmatrix}\boldsymbol{\Sigma}_{aa} &amp; \boldsymbol{\Sigma}_{ab} \\ \boldsymbol{\Sigma}_{ba} &amp; \boldsymbol{\Sigma}_{bb} \end{bmatrix}$이다. 
</p>
</div>
</div>

<div id="outline-container-orga5fbff1" class="outline-2">
<h2 id="orga5fbff1"><span class="section-number-2">4</span> Conditional Distribution</h2>
<div class="outline-text-2" id="text-4">
<p>
두 개의 확률변수 $a, b$가 주어졌을 때 조건부 확률분포 $p(a|b=b_{0})$가 가우시안 분포를 따른다고 하면
</p>

\begin{equation}
  \begin{aligned}
    p(a | b=b) &amp; = \frac{p(a,b)}{p(b)} = \frac{p(b | a)p(a)}{p(b)} = \eta \cdot p(a, b)p(a) \\
    &amp; \sim \mathcal{N}(\boldsymbol{\mu}_{a|b}, \boldsymbol{\Sigma}_{a|b})
  \end{aligned}
\end{equation}
<p>
가 된다 이 때 평균 $\boldsymbol{\mu}_{a|b}$과 분산 $\boldsymbol{\Sigma}_{a|b}$은
</p>

\begin{equation}
  \begin{aligned}
    &amp; \boldsymbol{\mu}_{a|b} = \boldsymbol{\mu}_{a} + \boldsymbol{\Sigma}_{ab}\boldsymbol{\Sigma}_{bb}^{-1}(b_{0} - \boldsymbol{\mu}_{b}) \\
    &amp; \boldsymbol{\Sigma}_{a|b} = \boldsymbol{\Sigma}_{aa} - \boldsymbol{\Sigma}_{ab}\boldsymbol{\Sigma}_{bb}^{-1}\boldsymbol{\Sigma}_{ab}^{\intercal}
  \end{aligned}
\end{equation}
<p>
과 같다.
</p>
</div>
</div>

<div id="outline-container-org466bcf8" class="outline-2">
<h2 id="org466bcf8"><span class="section-number-2">5</span> Recursive Bayes Filter</h2>
<div class="outline-text-2" id="text-5">
<p>
시간 $t$에 대하여 로봇의 위치에 대한 상태 $\mathbf{x}_{t}$와 관측값 $\mathbf{z}_{t}$그리고 제어입력 $\mathbf{u}_{t}$가 주어졌을 때 $\text{bel}(\mathbf{x}_{t})$(Belief of $\mathbf{x}_{t}$)는 다음과 같이 정의한다.
</p>

\begin{equation}
  \begin{aligned}
    \text{bel}(\mathbf{x}_{t}) = p(\mathbf{x}_{t} \ | \ \mathbf{z}_{1:t}, \mathbf{u}_{1:t})
  \end{aligned}
\end{equation}
<p>
<b>$\text{bel}(\mathbf{x}_{t})$는 처음부터 $t$초까지 센서를 통한 관측과 제어입력으로 인해 현재 로봇이 $\mathbf{x}$에 위치할 확률을 의미한다.</b> 해당 식을 Markov Assumption과 Bayesian Rule을 사용하여 전개하면 재귀적인 필터를 유도할 수 있고 이를 Recursive Bayes Filter라고 한다. Recursive Bayes Filter 다음과 같다.
</p>

\begin{equation}
  \begin{aligned}
    &amp; \text{bel}(\mathbf{x}_{t}) = \eta \cdot p( \mathbf{z}_{t} \ | \  \mathbf{x}_{t})\overline{\text{bel}}(\mathbf{x}_{t}) \\
    &amp; \overline{\text{bel}}(\mathbf{x}_{t}) = \int p(\mathbf{x}_{t} \ | \ \mathbf{x}_{t-1}, \mathbf{u}_{t})\text{bel}(\mathbf{x}_{t-1})\\
  \end{aligned}
\end{equation}
<p>
Recursive Bayes Filter는 위와 같이 이전 스텝의 $\text{bel}(\mathbf{x}_{t-1})$로부터 현재 스텝의 $\text{bel}(\mathbf{x}_{t})$를 구할 수 있으므로 재귀 필터라고 부른다. <b>이 때, $p( \mathbf{z}_{t} \ | \ \mathbf{x}_{t})$를 관측 모델(observation model)이라고 부르며 $&int; p(\mathbf{x}_{t} \ | \ \mathbf{x}_{t-1},\mathbf{u}_{t})$를 모션 모델(motion model)이라고 부른다. $\text{bel}(\mathbf{x}_{t})$가 가우시안 분포를 따르는 경우 이를 특별히 칼만 필터(kalman filter)라고 한다.</b>
</p>

\begin{equation}
  \begin{aligned}
    \text{bel}(\mathbf{x}_{t}) \sim \mathcal{N}(\boldsymbol{\mu}, \boldsymbol{\Sigma}) \quad \text{(Kalman Filter)}
  \end{aligned}
\end{equation}
</div>
</div>


<div id="outline-container-org9cb8881" class="outline-2">
<h2 id="org9cb8881"><span class="section-number-2">6</span> Kalman Filter</h2>
<div class="outline-text-2" id="text-6">
<p>
시간 $t$에 로봇의 위치를 $\mathbf{x}_{t}$, 로봇의 센서로 부터 관측한 값을 $\mathbf{z}_{t}$, 로봇의 제어입력을 $\mathbf{u}_{t}$라고 하면 이를 통해 <b>모션 모델(motion model)과 관측 모델(observation model)을 정의할 수 있다. 이 때, 모션모델과 관측모델은 선형이어야(linear model) 한다는 제약조건이 있다.</b> 모션모델과 관측모델은 다음과 같다.
</p>

\begin{equation}
  \begin{aligned}
    &amp; \text{Motion Model: } &amp; \mathbf{x}_{t} = \mathbf{A}\mathbf{x}_{t-1} + \mathbf{B}\mathbf{u}_{t} + \epsilon_{t} \\
    &amp; \text{Observation Model: } &amp; \mathbf{z}_{t} = \mathbf{C}_{t}\mathbf{x}_{t} + \delta_{t} 
  \end{aligned}
\end{equation}
<p>
$&epsilon;_{t} &sim; \mathcal{N}(0, \mathbf{R}_{t})$는 모션 모델의 노이즈를 의미하고 $&delta;_{t} &sim; \mathcal{N}(0, \mathbf{Q}_{t})$는 관측 모델의 노이즈를 의미한다. 초기값 $\text{bel}(\mathbf{x}_{0})$은 다음과 같이 주어진다.
</p>

\begin{equation}
  \begin{aligned}
    \text{bel}(\mathbf{x}_{0}) \sim \mathcal(\boldsymbol{\mu}_{0}, \boldsymbol{\Sigma}_{0})
  \end{aligned}
\end{equation}
<p>
시간 $t$에서 Belief가 모두 가우시안 분포를 따른다고 가정하면
</p>

\begin{equation}
  \begin{aligned}
    &amp; \text{bel}(\mathbf{x}_{t}) = p(\mathbf{x}_{t} \ | \ \mathbf{z}_{1:t},\mathbf{u}_{1:t}) \sim \mathcal{N}(\boldsymbol{\mu}_{t}, \boldsymbol{\Sigma}_{t}) \\
    &amp; \overline{\text{bel}}(\mathbf{x}_{t}) \sim \mathcal{N}(\overline{\boldsymbol{\mu}}_{t}, \overline{\boldsymbol{\Sigma}}_{t}) \\
  \end{aligned}
\end{equation}
<p>
과 같고 <b>$\overline{\text{bel}}(\mathbf{x}_{t})$를 Prediction Step, $\text{bel}(\mathbf{x}_{t})$를 Correction Step이라고 한다.</b> 칼만필터는 Prediction Step에서 이전 스텝의 값과 모션 모델을 사용하여 예측값을 먼저 구한 후 Correction Step에서 관측값과 관측 모델을 사용하여 보정된 값을 구하는 방식으로 동작한다.
</p>
</div>

<div id="outline-container-org3d1efce" class="outline-3">
<h3 id="org3d1efce"><span class="section-number-3">6.1</span> Prediction step</h3>
<div class="outline-text-3" id="text-6-1">
<p>
Prediction Step은 $\overline{\text{bel}}(\mathbf{x}_{t})$를 구하는 과정을 말한다. $\overline{\text{bel}}(\mathbf{x}_{t})$는 가우시안 분포를 따르므로 평균 $\overline{\boldsymbol{\mu}}_{t}$과 분산 $\overline{\boldsymbol{\Sigma}}_{t}$을 각각 구해보면
</p>

\begin{equation}
  \begin{aligned}
    &amp; \overline{\boldsymbol{\mu}}_{t} = \mathbf{A}_{t}\boldsymbol{\mu}_{t-1} + \mathbf{B}_{t}\boldsymbol{\mu}_{t} \\
    &amp; \overline{\boldsymbol{\Sigma}}_{t} = \mathbf{A}_{t}\boldsymbol{\Sigma}_{t}\mathbf{A}_{t}^{\intercal} + \mathbf{R}_{t}
  \end{aligned}
\end{equation}
<p>
같이 구할 수 있다.
</p>
</div>
</div>

<div id="outline-container-org6c30b8e" class="outline-3">
<h3 id="org6c30b8e"><span class="section-number-3">6.2</span> Correction Step</h3>
<div class="outline-text-3" id="text-6-2">
<p>
Correction Step은 $\text{bel}(\mathbf{x}_{t})$를 구하는 과정을 말한다. $\text{bel}(\mathbf{x}_{t})$는 가우시안 분포를 따르므로 평균 $\boldsymbol{\mu}_{t}$을 구해보면
</p>

\begin{equation}
  \begin{aligned}
    \boldsymbol{\mu}_{t} &amp; = \boldsymbol{\mu}_{x|z} \\
    &amp; = \boldsymbol{\mu}_{x} + \boldsymbol{\Sigma}_{xz}\boldsymbol{\Sigma}_{zz}^{-1}(\mathbf{z}_{t}-\boldsymbol{\mu}_{t}) \\
    &amp; = \overline{\boldsymbol{\mu}}_{t} + \overline{\boldsymbol{\Sigma}}_{t}\mathbf{C}_{t}^{\intercal}(\mathbf{C}_{t}\overline{\boldsymbol{\Sigma}}_{t}\mathbf{C}_{t}^{\intercal} + \mathbf{Q}_{t})^{-1}( \mathbf{z}_{t} - \mathbf{C}_{t}\overline{\boldsymbol{\mu}}_{t}) \\
    &amp; = \overline{\boldsymbol{\mu}}_{t} + \mathbf{K}_{t}( \mathbf{z}_{t} - \mathbf{C}_{t}\overline{\boldsymbol{\mu}}_{t})
  \end{aligned}
\end{equation}
<p>
와 같고 분산 $\boldsymbol{\Sigma}_{t}$를 구해보면
</p>

\begin{equation}
  \begin{aligned}
    \boldsymbol{\Sigma}_{t} &amp; = \boldsymbol{\Sigma}_{x|z} \\
    &amp; = \boldsymbol{\Sigma}_{xx} - \boldsymbol{\Sigma}_{zx}\boldsymbol{\Sigma}_{zz}^{-1}\boldsymbol{\Sigma}_{xz} \\
    &amp; = \overline{\boldsymbol{\Sigma}}_{t} - \overline{\boldsymbol{\Sigma}}_{t}\mathbf{C}_{t}^{\intercal}(\mathbf{C}_{t}\overline{\boldsymbol{\Sigma}}_{t}\mathbf{C}_{t}^{\intercal} + \mathbf{Q}_{t})^{-1}\mathbf{C}_{t}\overline{\boldsymbol{\Sigma}}_{t} \\
    &amp; = (\mathbf{I} - \mathbf{K}_{t}\mathbf{C}_{t})\overline{\boldsymbol{\Sigma}}_{t}
  \end{aligned}
\end{equation}
<p>
이다. 이 때, $\mathbf{K}_{t}$는 Kalman Gain를 의미하며
</p>

\begin{equation}
  \begin{aligned}
    \mathbf{K}_{t} = \overline{\boldsymbol{\Sigma}}_{t}\mathbf{C}_{t}^{\intercal}(\mathbf{C}_{t}\overline{\boldsymbol{\Sigma}}_{t}\mathbf{C}_{t}^{\intercal} + \mathbf{Q}_{t})^{-1}
  \end{aligned}
\end{equation}
<p>
이다.
</p>
</div>
</div>

<div id="outline-container-orgd138f50" class="outline-3">
<h3 id="orgd138f50"><span class="section-number-3">6.3</span> Pseudo code</h3>
<div class="outline-text-3" id="text-6-3">
<p>
칼만필터를 함수로 표현하면 다음과 같다. 
</p>

\begin{equation}
\begin{aligned}
&amp; \text{KalmanFilter}(\mu_{t-1}, \Sigma_{t-1}, u_{t}, z_{t}) \{ \\
&amp; \quad\quad \text{(Prediction Step)}\\
&amp; \quad\quad \overline{\mu}_{t} = \mathbf{A}_{t}\mu_{t-1} + \mathbf{B}_{t}u_{t}\\
&amp; \quad\quad \overline{\Sigma}_{t} = \mathbf{A}_{t}\Sigma_{t-1}\mathbf{A}_{t}^{\intercal} + \mathbf{R}_{t}\\
&amp; \\
&amp; \quad\quad \text{(Correction Step)} \\
&amp; \quad\quad \mathbf{K}_{t} = \overline{\Sigma}_{t}\mathbf{C}_{t}^{\intercal}(\mathbf{C}_{t}\overline{\Sigma}_{t}\mathbf{C}_{t}^{\intercal} + \mathbf{Q}_{t})^{-1} \\
&amp; \quad\quad \mu_{t} = \overline{\mu}_{t} + \mathbf{K}_{t}(z_{t} - \mathbf{C}_{t}\overline{\mu}_{t}) \\
&amp; \quad\quad \Sigma_{t} = (\mathbf{I} - \mathbf{K}_{t}\mathbf{C}_{t})\overline{\Sigma}_{t} \\
&amp; \quad\quad \text{return} \ \ \mu_{t}, \Sigma_{t} \\
&amp;   \}
\end{aligned}
\end{equation}
</div>
</div>
</div>

<div id="outline-container-org5f534f4" class="outline-2">
<h2 id="org5f534f4"><span class="section-number-2">7</span> Extended Kalman Filter</h2>
<div class="outline-text-2" id="text-7">
<p>
칼만필터는 모션모델과 관측모델이 선형이라는 가정 하에 상태를 추정한다. 하지만 현실세계의 대부분의 현상들은 비선형으로 모델링되므로 앞서 정의한 칼만필터를 그대로 적용하면 정상적으로 동작하지 않는다. 비선형의 모션모델과 관측모델에서도 칼만필터를 사용하기 위해 확장칼만필터(Extended Kalman Filter,EKF)가 제안되었다. <b>확장칼만필터는 1차 테일러 근사(1st talyor approximation)을 사용하여 비선형 모델을 선형 모델로 근사한 후 칼만필터를 적용하는 방법을 사용한다.</b>
</p>

<p>
확장칼만필터에서 모션모델과 관측모델은 다음과 같다.
</p>

\begin{equation}
  \begin{aligned}
    &amp; \text{Motion Model: } &amp; \mathbf{x}_{t} = \mathbf{g}(\mathbf{u}_{t},\mathbf{x}_{t-1}) + \epsilon_{t} \\
    &amp; \text{Observation Model: } &amp;  \mathbf{z}_{t} = \mathbf{h}(\mathbf{x}_{t}) + \delta_{t}
  \end{aligned}
\end{equation}
<p>
위 식에서 $\mathbf{g}(&sdot;,&sdot;)$은 비선형 모션모델을 의미하고 $\mathbf{h}(&sdot;)$은 비선형 관측모델을 의미한다. $\mathbf{x}_{t-1}=\boldsymbol{\mu}_{t-1},\ \mathbf{x}_{t} = \overline{\boldsymbol{\mu}}_{t}$에서 1차 테일러 근사를 수행하면 다음과 같다.
</p>

\begin{equation}
  \begin{aligned}
    &amp; \mathbf{x}_{t} \approx \mathbf{g}(\mathbf{u}_{t},\boldsymbol{\mu}_{t-1}) + \mathbf{G}_{t}(\mathbf{x}_{t-1} - \boldsymbol{\mu}_{t-1}) + \epsilon_{t} \\
    &amp;  \mathbf{z}_{t} \approx \mathbf{h}(\overline{\boldsymbol{\mu}}_{t}) + \mathbf{H}_{t}(\mathbf{x}_{t} - \overline{\boldsymbol{\mu}}_{t}) + \delta_{t}
  \end{aligned}
\end{equation}
<p>
이 때, $\mathbf{G}_{t}$는 모션모델의 자코비안 행렬을 의미하며 $\mathbf{H}_{t}$는 관측모델의 자코비안 행렬을 의미한다.
</p>

\begin{equation}
  \begin{aligned}
    &amp; \mathbf{G}_{t} = \frac{\partial \mathbf{g}(\mathbf{u}_{t},\mathbf{x}_{t-1})}{\partial \mathbf{x}_{t-1}}\bigg|_{\mathbf{x}_{t-1}=\boldsymbol{\mu}_{t-1}} &amp; \mathbf{H}_{t} = \frac{\partial \mathbf{h}(\mathbf{x}_{t})}{\partial \mathbf{x}_{t}}\bigg|_{\mathbf{x}_{t}=\boldsymbol{\mu}_{t}} \\
  \end{aligned}
\end{equation}
</div>

<div id="outline-container-org4452ac6" class="outline-3">
<h3 id="org4452ac6"><span class="section-number-3">7.1</span> Pseudo code</h3>
<div class="outline-text-3" id="text-7-1">
<p>
확장칼만필터를 함수로 표현하면 다음과 같다. 
</p>

\begin{equation}
\begin{aligned}
&amp; \text{ExtendedKalmanFilter}(\mu_{t-1}, \Sigma_{t-1}, u_{t}, z_{t}) \{ \\
&amp; \quad\quad \text{(Prediction Step)}\\
&amp; \quad\quad \overline{\mu}_{t} = \mathbf{g}(\mathbf{u}_{t}, \boldsymbol{mu}_{t-1}) \\
&amp; \quad\quad \overline{\Sigma}_{t} = \mathbf{G}_{t}\Sigma_{t-1}\mathbf{G}_{t}^{\intercal} + \mathbf{R}_{t}\\
&amp; \\
&amp; \quad\quad \text{(Correction Step)} \\
&amp; \quad\quad \mathbf{K}_{t} = \overline{\Sigma}_{t}\mathbf{H}_{t}^{\intercal}(\mathbf{H}_{t}\overline{\Sigma}_{t}\mathbf{H}_{t}^{\intercal} + \mathbf{Q}_{t})^{-1} \\
&amp; \quad\quad \mu_{t} = \overline{\mu}_{t} + \mathbf{K}_{t}(z_{t} - \mathbf{h}(\overline{\mu}_{t})) \\
&amp; \quad\quad \Sigma_{t} = (\mathbf{I} - \mathbf{K}_{t}\mathbf{H}_{t})\overline{\Sigma}_{t} \\
&amp; \quad\quad \text{return} \ \ \mu_{t}, \Sigma_{t} \\
&amp;   \}
\end{aligned}
\end{equation}
</div>
</div>
</div>

<div id="outline-container-org5706b9e" class="outline-2">
<h2 id="org5706b9e"><span class="section-number-2">8</span> References</h2>
<div class="outline-text-2" id="text-8">
<p>
<a href="http://jinyongjeong.github.io/2017/02/14/lec03_kalman_filter_and_EKF/">Jinyong Jeong's Blog</a>
</p>
</div>
</div>
